{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37114c77",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96d19a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6169395f",
   "metadata": {},
   "source": [
    "Baixar gloVe em http://nlp.stanford.edu/data/glove.840B.300d.zip e adicionar nesse diret√≥rio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc4a4a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -q glove.840B.300d.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa3459e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601276b8",
   "metadata": {},
   "source": [
    "# Rotten Tomatoes Movie Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0a5c194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this film seems thirsty for reflection , itsel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the movie's thesis -- elegant technology for t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tries too hard to be funny in a way that's too...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>disturbingly superficial in its approach to th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>an ugly , pointless , stupid movie .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  this film seems thirsty for reflection , itsel...       1\n",
       "1  the movie's thesis -- elegant technology for t...       1\n",
       "2  tries too hard to be funny in a way that's too...       0\n",
       "3  disturbingly superficial in its approach to th...       0\n",
       "4               an ugly , pointless , stupid movie .       0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define file paths\n",
    "neg_file_path = 'rtmr/rt-polarity.neg'\n",
    "pos_file_path = 'rtmr/rt-polarity.pos'\n",
    "\n",
    "# Read files\n",
    "with open(neg_file_path, 'r', encoding='latin-1') as f:\n",
    "    neg_lines = f.readlines()\n",
    "\n",
    "with open(pos_file_path, 'r', encoding='latin-1') as f:\n",
    "    pos_lines = f.readlines()\n",
    "\n",
    "# Create DataFrames\n",
    "df_neg = pd.DataFrame({'text': [line.strip() for line in neg_lines], 'target': 0})\n",
    "df_pos = pd.DataFrame({'text': [line.strip() for line in pos_lines], 'target': 1})\n",
    "\n",
    "# Combine them\n",
    "df = pd.concat([df_neg, df_pos], ignore_index=True)\n",
    "\n",
    "# Optional: shuffle the dataset\n",
    "df = df.sample(frac=1, random_state=RANDOM_STATE).reset_index(drop=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e523140a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(df[\"text\"], df[\"target\"], test_size=0.2, random_state=RANDOM_STATE, stratify=df[\"target\"])\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=RANDOM_STATE, stratify=y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ecaa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.to_csv(\"rtmr/X_train.csv\", index=False)\n",
    "# y_train.to_csv(\"rtmr/y_train.csv\", index=False)\n",
    "\n",
    "# X_val.to_csv(\"rtmr/X_val.csv\", index=False)\n",
    "# y_val.to_csv(\"rtmr/y_val.csv\", index=False)\n",
    "\n",
    "# X_test.to_csv(\"rtmr/X_test.csv\", index=False)\n",
    "# y_test.to_csv(\"rtmr/y_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64ca1a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num train samples: 8529\n",
      "Num val samples  : 1066\n",
      "Num test samples : 1067\n"
     ]
    }
   ],
   "source": [
    "X_train_df = pd.read_csv(\"rtmr/X_train.csv\")\n",
    "X_val_df   = pd.read_csv(\"rtmr/X_val.csv\")\n",
    "X_test_df  = pd.read_csv(\"rtmr/X_test.csv\")\n",
    "\n",
    "# Flatten to list of strings\n",
    "X_train = X_train_df.iloc[:, 0].astype(str)\n",
    "X_val   = X_val_df.iloc[:, 0].astype(str)\n",
    "X_test  = X_test_df.iloc[:, 0].astype(str)\n",
    "\n",
    "# Check shapes\n",
    "print(\"Num train samples:\", len(X_train))\n",
    "print(\"Num val samples  :\", len(X_val))\n",
    "print(\"Num test samples :\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3982d2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_embeddings(glove_path=\"glove.840B.300d.txt\"):\n",
    "    embeddings = {}\n",
    "    with open(glove_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.rstrip().split(' ')\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings[word] = vector\n",
    "    return embeddings\n",
    "\n",
    "glove_embeddings = load_glove_embeddings()\n",
    "embedding_dim = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca9e3407",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "with open(\"rtmr/tokenizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "\n",
    "# Convert to sequences\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_val_seq   = tokenizer.texts_to_sequences(X_val)\n",
    "X_test_seq  = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Pad sequences to the same length\n",
    "max_len = 100  # or compute dynamically via np.percentile or np.max\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='post', truncating='post')\n",
    "X_val_pad   = pad_sequences(X_val_seq, maxlen=max_len, padding='post', truncating='post')\n",
    "X_test_pad  = pad_sequences(X_test_seq, maxlen=max_len, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38ff05bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"rtmr/X_train_pad.npy\", X_train_pad)\n",
    "np.save(\"rtmr/X_val_pad.npy\", X_val_pad)\n",
    "np.save(\"rtmr/X_test_pad.npy\", X_test_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2785c9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "vocab_size = len(word_index) + 1  # +1 for padding token\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    vector = glove_embeddings.get(word)\n",
    "    if vector is not None:\n",
    "        embedding_matrix[i] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8243f9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"rtmr/embedding_matrix.npy\", embedding_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textbugger",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
